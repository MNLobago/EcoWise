{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9908388,"sourceType":"datasetVersion","datasetId":6087721},{"sourceId":9908540,"sourceType":"datasetVersion","datasetId":6087841},{"sourceId":9908573,"sourceType":"datasetVersion","datasetId":6087857}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Google Generative AI and CSV Processing\n\n## Installation\n\nFirst, ensure that you have the required package installed. You can do this by running:\n\n```python\n%pip install -U -q \"google-generativeai>=0.8.3\"","metadata":{}},{"cell_type":"code","source":"%pip install -U -q \"google-generativeai>=0.8.3\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:27:40.671053Z","iopub.execute_input":"2024-11-14T20:27:40.671521Z","iopub.status.idle":"2024-11-14T20:28:11.014062Z","shell.execute_reply.started":"2024-11-14T20:27:40.671462Z","shell.execute_reply":"2024-11-14T20:28:11.012693Z"}},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import google.generativeai as genai\nfrom IPython.display import HTML, Markdown, display","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:28:11.016358Z","iopub.execute_input":"2024-11-14T20:28:11.016767Z","iopub.status.idle":"2024-11-14T20:28:12.230058Z","shell.execute_reply.started":"2024-11-14T20:28:11.016713Z","shell.execute_reply":"2024-11-14T20:28:12.228917Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Configuration\nSet your Google API key for the generative AI model:\n","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\ngenai.configure(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:28:12.232042Z","iopub.execute_input":"2024-11-14T20:28:12.232557Z","iopub.status.idle":"2024-11-14T20:28:12.451145Z","shell.execute_reply.started":"2024-11-14T20:28:12.232515Z","shell.execute_reply":"2024-11-14T20:28:12.450170Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nimport re \n\n# Parameters\nfile_paths = [\n    '/kaggle/input/model-1data/model_responses_with_time_tqdm1S .csv',\n    '/kaggle/input/model-2data/model_responses_with_time_tqdm2S.csv',\n    '/kaggle/input/model-3data/model_responses_with_time_tqdm3S.csv'\n]\n\noutput_paths = [\n    './Final_evaluated_1.csv',\n    './Final_evaluated_2.csv',\n    './Final_evaluated_3.csv'\n]\n\nmax_tokens = 200  # Maximum tokens for the model response\n\n# Initialize the Gemini model for evaluating answers.\nshort_model = genai.GenerativeModel(\n    'gemini-1.5-flash',\n    generation_config=genai.GenerationConfig(max_output_tokens=max_tokens)\n)\n\ndef extract_and_evaluate(row):\n    \"\"\"\n    Evaluates the model's answer against the expected answer.\n\n    Parameters:\n    row (pd.Series): A row of the DataFrame containing 'question', 'expected_answer', 'model_answer', and 'Max_Score'.\n\n    Returns:\n    tuple: Extracted model answer, score, and reasoning.\n    \"\"\"\n    question = row['question']\n    expected_answer = row['expected_answer']\n    model_answer = row['model_answer']\n    max_score = row['Max_Score']\n\n    # Extract the part of the model answer that is actually the answer\n    answer_start = model_answer.find(\"Answer:\") + len(\"Answer:\")\n    model_answer_extracted = model_answer[answer_start:].strip() if answer_start > -1 else \"No valid answer found.\"\n\n    # Prepare the evaluation prompt\n    prompt = (\n        f\"Given the question below, evaluate the provided answer and score it from 0 to {max_score} based on its alignment with the expected answer.\\n\"\n        f\"Question: {question}\\n\"\n        f\"Expected Answer: {expected_answer}\\n\"\n        f\"Model Answer: {model_answer_extracted}\\n\"\n        \"Please provide a score and brief reasoning, focusing on conceptual alignment.\"\n    )\n\n    # Use the model to evaluate the extracted answer\n    try:\n        evaluation_response = short_model.generate_content(prompt).text.strip()\n        \n        # Extract score and reasoning using regex\n        score_match = re.search(r'Score:\\s*[\\*]*(\\d*\\.?\\d+)[\\*]*', evaluation_response)\n        score = float(score_match.group(1)) if score_match else 0\n        \n        reasoning_match = re.search(r'Reasoning:\\s*([\\s\\S]*)', evaluation_response)\n        reasoning = reasoning_match.group(1).strip() if reasoning_match else \"Reasoning not provided.\"\n        \n    except Exception as e:\n        print(f\"Error parsing evaluation response for question '{question}': {e}\")\n        score = 0\n        reasoning = \"Error in evaluation.\"\n\n    return model_answer_extracted, score, reasoning\n\n# Process each file\nfor i, (data_path, output_path) in enumerate(zip(file_paths, output_paths)):\n    # Load the dataset\n    df = pd.read_csv(data_path)  # Make sure this path is correct\n\n    # Apply the function to all rows in the DataFrame\n    results = df.apply(extract_and_evaluate, axis=1)\n\n    # Expand the results into separate columns\n    df['Extracted Model Answer'] = results.str[0]\n    df['Gemini Score'] = results.str[1]\n    df['Evaluation Reasoning'] = results.str[2]\n\n    # Save the updated DataFrame back to CSV\n    df.to_csv(output_path, index=False)\n\n    # Print the sum of the Gemini Score for the current file\n    total_score = df['Gemini Score'].sum()\n    print(f\"Total Gemini Score for {data_path}: {total_score}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:28:12.453216Z","iopub.execute_input":"2024-11-14T20:28:12.453608Z","iopub.status.idle":"2024-11-14T20:31:33.547964Z","shell.execute_reply.started":"2024-11-14T20:28:12.453566Z","shell.execute_reply":"2024-11-14T20:31:33.546572Z"}},"outputs":[{"name":"stdout","text":"Total Gemini Score for /kaggle/input/model-1data/model_responses_with_time_tqdm1S .csv: 45.9\nTotal Gemini Score for /kaggle/input/model-2data/model_responses_with_time_tqdm2S.csv: 48.58\nTotal Gemini Score for /kaggle/input/model-3data/model_responses_with_time_tqdm3S.csv: 47.3\n","output_type":"stream"}],"execution_count":4}]}